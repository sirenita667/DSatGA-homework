{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Conceptual\n",
    "\n",
    "###  1.  WHat is the difference between train and test set?\n",
    "\n",
    "Develop model using training set and measure model's performance on test set.  If training set and test set and pulled from the same dataset, test set is less than 50%...in cross_validation.train_test_split, default is set at .25 (25%).\n",
    "\n",
    "\n",
    "###  2.  Why is it important to have a seperate data set for training?\n",
    "\n",
    "If you test using the same data you used to train a model, you are training the model to memorize the data pretty much.  \n",
    "\n",
    "###  3.  What are some advantages and disadvantages of the KNN algorithm?\n",
    "\n",
    "Advantage:  easy to use, does not assume data follows thories\n",
    "\n",
    "Disadvantages:  no training time; high memory usage as KNN tests every single point\n",
    "\n",
    "###  4.  Explain in your own words the bias variance tradeoff\n",
    "\n",
    "High bias/low variance means the model is as equidistant from all points and underfitted; low bias/high variance means the model does an excellent of reducing MSE to 0 and is overfitted.\n",
    "\n",
    "###  5.  Do you think KNN suffers from high bias or high variance?\n",
    "\n",
    "k=1, or \"the nearest neighbor,\" means every point is fitted and so suffers from low bias/high variance.  A higher k reduces variance and increases bias.\n",
    "\n",
    "###  6.  List some possible solutions when suffering from high variance.\n",
    "\n",
    "fewer features, more training examples, increasing regularization parameter (alpha), or even including a regularization parameter with Ridge and/or Lasso  regression.\n",
    "\n",
    "###  7.  List some possible solutions when suffering from high bias.\n",
    "\n",
    "more features, especially polynomial features, decreasing regularization parameter alpha.\n",
    "\n",
    "###  8.  Would you choose K when doing K Nearest Neighbors?\n",
    "\n",
    "yes; K indicates the number of neighbors you want to include in regression analysis.  else default for sklearn.neighbors.NearestNeighbors is n_neighbors=5.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Practical\n",
    "\n",
    "\n",
    "###1.  perform regression on the prostate data set..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###  importing...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import grid_search\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "0 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "1 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "2 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "3 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "4  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "0     T  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('https://raw.githubusercontent.com/galvin-mj/DAT_ATL_15/master/Datasets/ProstateCancer.csv')\n",
    "del d['Unnamed: 0']\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = d[d['train']=='T']\n",
    "de = d[d['train']=='F']\n",
    "\n",
    "del dtr['train']\n",
    "del de['train']\n",
    "\n",
    "xtr = d[d['train']=='T'][['lcavol','lweight','age','lbph','svi','lcp','gleason','pgg45']]\n",
    "ytr = d[d['train']=='T'][['lpsa']]\n",
    "xe = d[d['train']=='F'][['lcavol','lweight','age','lbph','svi','lcp','gleason','pgg45']]\n",
    "ye = d[d['train']=='F'][['lpsa']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#xtr, ytr, xe, ye are xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient [[ 0.57654319  0.61402    -0.01900102  0.14484808  0.73720864 -0.20632423\n",
      "  -0.02950288  0.00946516]]\n",
      "intercept [ 0.42917013]\n",
      "mean squared error for linear regression: 0.521274005508\n"
     ]
    }
   ],
   "source": [
    "lr_rgr = linear_model.LinearRegression()\n",
    "lr_rgr.fit(xtr, ytr)\n",
    "\n",
    "print(\"coefficient {}\".format(lr_rgr.coef_))\n",
    "print(\"intercept {}\".format(lr_rgr.intercept_))\n",
    "\n",
    "\n",
    "lr_mse = mean_squared_error(ye, lr_rgr.predict(xe))\n",
    "print('mean squared error for linear regression: {}'.format(lr_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.733155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.485215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.227642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.262938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.556886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.489203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>0.342428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lpsa</th>\n",
       "      <td>0.733155</td>\n",
       "      <td>0.485215</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.262938</td>\n",
       "      <td>0.556886</td>\n",
       "      <td>0.489203</td>\n",
       "      <td>0.342428</td>\n",
       "      <td>0.448048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "lpsa     0.733155  0.485215  0.227642  0.262938  0.556886  0.489203  0.342428   \n",
       "\n",
       "            pgg45      lpsa  \n",
       "lcavol   0.483161  0.733155  \n",
       "lweight  0.074166  0.485215  \n",
       "age      0.275806  0.227642  \n",
       "lbph    -0.030404  0.262938  \n",
       "svi      0.481358  0.556886  \n",
       "lcp      0.662533  0.489203  \n",
       "gleason  0.757056  0.342428  \n",
       "pgg45    1.000000  0.448048  \n",
       "lpsa     0.448048  1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64234204467\n",
      "1.07103372842 , best model with k = 3\n",
      "1.20880435689\n",
      "1.22369952425\n",
      "1.26200164893\n",
      "1.22008243112\n"
     ]
    }
   ],
   "source": [
    "k1 = neighbors.KNeighborsRegressor(n_neighbors = 1)\n",
    "kk1 = k1.fit(xtr, ytr).predict(xe)\n",
    "k1_mse = mean_squared_error(ye, kk1)\n",
    "\n",
    "\n",
    "k3 = neighbors.KNeighborsRegressor(n_neighbors = 3)\n",
    "kk3 = k3.fit(xtr, ytr).predict(xe)\n",
    "k3_mse = mean_squared_error(ye,kk3)\n",
    "\n",
    "\n",
    "k5 = neighbors.KNeighborsRegressor()\n",
    "kk5 = k5.fit(xtr, ytr).predict(xe)\n",
    "k5_mse = mean_squared_error(ye,kk5)\n",
    "\n",
    "k7 = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
    "kk7 = k7.fit(xtr, ytr).predict(xe)\n",
    "k7_mse = mean_squared_error(ye, kk7)\n",
    "\n",
    "k2 = neighbors.KNeighborsRegressor(n_neighbors = 2)\n",
    "kk2 = k2.fit(xtr, ytr).predict(xe)\n",
    "k2_mse = mean_squared_error(ye, kk2)\n",
    "\n",
    "k4 = neighbors.KNeighborsRegressor(n_neighbors = 4)\n",
    "kk4 = k4.fit(xtr, ytr).predict(xe)\n",
    "k4_mse = mean_squared_error(ye, kk4)\n",
    "\n",
    "print k1_mse\n",
    "print k3_mse,\", best model with k = 3\"\n",
    "print k5_mse\n",
    "print k7_mse\n",
    "print k2_mse\n",
    "print k4_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ridge, cv = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid=[{'alpha': array([  1.00000e-08,   3.33454e-04, ...,   9.99667e-01,   1.00000e+00])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'alpha':np.linspace(1e-8,1,3000)}]\n",
    "rrgr8 = linear_model.Ridge(normalize = True)\n",
    "rcv8 = grid_search.GridSearchCV(rrgr8, param_grid, cv = 8)\n",
    "rcv8.fit(xtr, ytr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.505103206405\n",
      "best parameters: {'alpha': 0.56718906734911645}\n",
      "best score: -29.1019145509\n",
      "best estimator: Ridge(alpha=0.56718906734911645, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=True, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "r_mse8 = mean_squared_error(ye, rcv8.best_estimator_.predict(xe))\n",
    "print (\"mean squared error: {}\".format(r_mse8))\n",
    "print (\"best parameters: {}\".format(rcv8.best_params_))\n",
    "print (\"best score: {}\".format(rcv8.best_score_))\n",
    "print (\"best estimator: {}\".format(rcv8.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ridge, cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid=[{'alpha': array([  1.00000e-08,   3.33454e-04, ...,   9.99667e-01,   1.00000e+00])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'alpha':np.linspace(1e-8,1,3000)}]\n",
    "rrgr = linear_model.Ridge(normalize = True)\n",
    "rcv = grid_search.GridSearchCV(rrgr, param_grid)\n",
    "rcv.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.531095735149\n",
      "best parameters: {'alpha': 1.0}\n",
      "best score: -6.15002409481\n",
      "best estimator: Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=True, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "r_mse = mean_squared_error(ye, rcv.best_estimator_.predict(xe))\n",
    "print (\"mean squared error: {}\".format(r_mse))\n",
    "print (\"best parameters: {}\".format(rcv.best_params_))\n",
    "print (\"best score: {}\".format(rcv.best_score_))\n",
    "print (\"best estimator: {}\".format(rcv.best_estimator_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###lasso regression, cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid=[{'alpha': array([  1.00000e-08,   3.33454e-04, ...,   9.99667e-01,   1.00000e+00])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'alpha':np.linspace(1e-8,1,3000)}]\n",
    "lrgr = linear_model.Lasso()\n",
    "lcv = grid_search.GridSearchCV(lrgr, param_grid)\n",
    "lcv.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.51232144955\n",
      "best parameters: {'alpha': 0.061020349503167724}\n",
      "best score: -5.9771789559\n",
      "best estimator: Lasso(alpha=0.061020349503167724, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "l_mse = mean_squared_error(ye, lcv.best_estimator_.predict(xe))\n",
    "print (\"mean squared error: {}\".format(l_mse))\n",
    "print (\"best parameters: {}\".format(lcv.best_params_))\n",
    "print (\"best score: {}\".format(lcv.best_score_))\n",
    "print (\"best estimator: {}\".format(lcv.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###lasso, cv = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=11, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid=[{'alpha': array([  1.00000e-08,   3.33454e-04, ...,   9.99667e-01,   1.00000e+00])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'alpha':np.linspace(1e-8,1,3000)}]\n",
    "lrgr = linear_model.Lasso()\n",
    "lcv1 = grid_search.GridSearchCV(lrgr, param_grid, cv = 11)\n",
    "lcv1.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error: 0.499981740972\n",
      "best parameters: {'alpha': 0.031343790946982329}\n",
      "best score: -78.6202482446\n",
      "best estimator: Lasso(alpha=0.031343790946982329, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "l_mse1 = mean_squared_error(ye, lcv1.best_estimator_.predict(xe))\n",
    "print (\"mean squared error: {}\".format(l_mse1))\n",
    "print (\"best parameters: {}\".format(lcv1.best_params_))\n",
    "print (\"best score: {}\".format(lcv1.best_score_))\n",
    "print (\"best estimator: {}\".format(lcv1.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.  were there any features that were highly correlated?\n",
    "\n",
    "\n",
    "LCAVOL, SVI, and LCP were pretty highly correlated to each other.\n",
    "Consequently LPSA was similarly highly correlated to these three features.\n",
    "\n",
    "\n",
    "PGG45 and Gleason were highly correlated to each other, with a slightly lower correlation between PGG45 and LCP.\n",
    "PGG45 and Gleason's correlation with LPSA is not as high as LPSA's correlation with LCAVOL, SVI, and LCP.\n",
    "\n",
    "\n",
    "\n",
    "### 3.  what features were the most important?\n",
    "\n",
    "SVI and LCAVOL\n",
    "\n",
    "###....unimportant?\n",
    "\n",
    "Age and PGG45\n",
    "\n",
    "###  4.  What model worked best?  \n",
    "\n",
    "The best model I could find produced a mean squared error of 0.499 and was a Lasso Regression with CV = 11 (number of \"folds\").\n",
    "\n",
    "###  5.  what difficulties did you have with this data set?\n",
    "\n",
    "i think that, for the number of features, the training set was maybe a bit small, but i also only realized that after reading: http://stackoverflow.com/questions/14813884/correlated-features-and-classification-accuracy.  Otherwise, i could not identify anything lacking while working through the exercises.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
